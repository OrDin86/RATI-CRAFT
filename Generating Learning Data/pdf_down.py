# ì •ë³´ê³µê°œ ì‚¬ì´íŠ¸ ê³µê°œ pdf ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ

import asyncio
from playwright.async_api import async_playwright
import re

async def download_pdfs(keyword="", max_downloads=5, page_num = 1):
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            executable_path="C:\Program Files\Google\Chrome\Application/chrome.exe", headless=False)  # headless=Trueë¡œ ì„¤ì •í•˜ë©´ ì°½ ì•ˆëœ¸
        context = await browser.new_context(accept_downloads=True)
        page = await context.new_page()

        # ì ‘ì†
        await page.goto("https://www.open.go.kr/othicInfo/infoList/orginlInfoList.do")
        await page.wait_for_load_state("networkidle")

        # ê²€ìƒ‰ì–´ ì…ë ¥
        try:
            await page.evaluate('''({ start, end }) => {
                const $ = window.jQuery;
                if (!$) throw new Error('jQuery not loaded');
                $('input[name="startDate"]').datepicker('setDate', start);
                $('input[name="endDate"]').datepicker('setDate', end);
            }''', {"start": "2024-01-01", "end": "2024-01-31"})
        except Exception as e:
            print("âŒ ë‚ ì§œ ì„¤ì • ì‹¤íŒ¨:", e)

        await page.fill("#kwd", '')
        await page.wait_for_timeout(1000)
        await page.keyboard.press("Enter")
        await page.wait_for_timeout(1500)
        await page.wait_for_load_state("networkidle")

        count = 0
        #page_num = 115
        await page.evaluate(f"goPageInfo({page_num})")
        await page.wait_for_load_state("networkidle")

        while count < max_downloads:
            print(f"ğŸ“„ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘...")
            
            await page.wait_for_timeout(2000)
            items = await page.query_selector_all("div.info_list li")
            if not items:
                print("âŒ í•­ëª© ì—†ìŒ, ì¢…ë£Œ")
                break
        
            # ê²€ìƒ‰ ê²°ê³¼ í•­ëª©ë“¤ ê°€ì ¸ì˜¤ê¸°
            items = await page.query_selector_all("div.info_list li")
    
            for i in range(len(items)):
                if count >= max_downloads:
                    break

                selector = f"div.info_list li:nth-child({i+1}) a"
                await page.wait_for_load_state("networkidle")
                href = await page.eval_on_selector(selector, "el => el.getAttribute('href')")
                await page.wait_for_load_state("networkidle")

                # ì •ê·œì‹ìœ¼ë¡œ goDetail ì¸ì íŒŒì‹±
                match = re.search(r"goDetail\('([^']+)','([^']+)','([^']+)','([^']+)'\)", href)

                if not match:
                    print(f"âŒ {i+1}ë²ˆì§¸ í•­ëª©: goDetail íŒŒì‹± ì‹¤íŒ¨")
                    continue

                doc_id, code, type_code, idx = match.groups()

                # ìƒì„¸í˜ì´ì§€ë¡œ ì´ë™
                await page.evaluate(f"goDetail('{doc_id}', '{code}', '{type_code}', '{idx}')")
                await page.wait_for_load_state("networkidle")

                try:
                    await page.wait_for_selector("a.btn_type05.down", timeout=2000)
                    await page.wait_for_load_state("networkidle")
                except Exception as e:
                    print("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨_2:", e)
                    
                    try:
                        await page.go_back()
                    except Exception as e:
                        print("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨_1:", e)
                        await browser.close()  # ë¸Œë¼ìš°ì € ë¨¼ì € ë‹«ê¸°
                        await download_restart(page_num)
                        return
                    
                    continue

                # wonmunStep1 ì¸ì ì¶”ì¶œ
                onclick = await page.eval_on_selector("a.btn_type05.down", "el => el.getAttribute('onclick')")
                #match = re.search(r"wonmunStep1\('([^']+)','([^']+)','([^']+)'\)", onclick)
                #match = re.search(r"wonmunStep1\('([^']+)',\s*'([^']+)',\s*'([^']+)'\)", onclick)
                #match = re.search(r"wonmunStep1\('([^']+)',\s*'([^']+)',\s*'([^']+)'(?:,\s*'([^']+)')?\)", onclick)
                #match = re.search(r"wonmunStep1\(\s*'([^']+)'\s*,\s*'([^']+)'\s*,\s*'([^']+)'\s*,\s*'([^']+)'\s*\)",onclick)
                match = re.search(r"wonmunStep1\(\s*'([^']+)'\s*,\s*'([^']+)'\s*,\s*'([^']+)'\s*(?:,\s*'([^']+)')?\s*\)",onclick)
                await page.wait_for_load_state("networkidle")

                if not match:
                    print(f"âŒ {i+1}ë²ˆì§¸ í•­ëª©: wonmunStep1 íŒŒì‹± ì‹¤íŒ¨")
                    await browser.close()
                    await download_restart(page_num)
                    #await page.go_back()
                    #await page.wait_for_load_state("networkidle")
                    return

                #wonmun_id, filename, public_flag = match.groups()

                groups = match.groups()

                if len(groups) == 3:
                    wonmun_id, filename, public_flag = groups
                elif len(groups) == 4:
                    wonmun_id, filename, public_flag, extra = groups
                else:
                    print("âŒ ì˜ˆìƒ ì™¸ì˜ ì¸ì ê°œìˆ˜")
                    ...
                    return

                number = str(page_num) + "_" + str(i + 1)

                # PDF ë‹¤ìš´ë¡œë“œ
                print(f"ğŸ“¥ {i+1}. {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...")

                try:
                    async with page.expect_download(timeout=10000) as download_info:
                        
                        # await page.evaluate(f"""() => {{
                        #     javascript:wonmunStep1('{wonmun_id}', '{filename}', '{public_flag}');
                        # }}""")

                        await page.evaluate(f"""() => {{
                            javascript:wonmunStep1('{wonmun_id}', '{filename}', '{public_flag}', '{extra if len(groups)==4 else '0'}');
                        }}""")

                    download = await download_info.value
                    #await download.save_as(r"I:\\doc_data\\" + "202401\\" + number + "_" + filename)
                    await download.save_as(r"E:\pdf\\" + number + "_" + filename)
                    print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")
                    count += 1
                except Exception as e:
                    count += 1                    
                    print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

                # ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°
                await page.wait_for_load_state("networkidle")
                await page.wait_for_timeout(1000)
                try:
                    await page.go_back()
                    await page.wait_for_load_state("networkidle")
                except Exception as e:
                    await page.evaluate(f"goPageInfo({next_page_num})")    
                    await page.wait_for_load_state("networkidle")          

            # ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            next_page_num = page_num + 1
            await page.wait_for_function("typeof goPageInfo === 'function'", timeout=2000)

            try:
                await page.evaluate(f"goPageInfo({next_page_num})")
            except Exception as e:
                print(f"ğŸš«{next_page_num} ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")                
                page_num = next_page_num
                await page.click("a[title='ë‹¤ìŒìœ¼ë¡œ']")  # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
                await page.wait_for_load_state("networkidle")
                continue

            await page.wait_for_load_state("networkidle")
            page_num = next_page_num

async def download_restart(page_num):
    
    await download_pdfs('', 300000, page_num)


asyncio.run(download_pdfs("", max_downloads=300000, page_num = 100))
